{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRo3_YXxZ296"
      },
      "source": [
        "# Install packages and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UomJosabaBVr",
        "outputId": "b1c6ffeb-1398-4dd2-c59e-402577b4b4f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ModelCompression'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 64 (delta 27), reused 51 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (64/64), 19.69 KiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "/content/ModelCompression/hw5\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m615.6/615.6 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/PredelinaAsya/ModelCompression.git\"\n",
        "%cd ModelCompression/hw5\n",
        "!pip3 install -qr \"requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AQh-aGJ0aTGw"
      },
      "outputs": [],
      "source": [
        "from ModelCompression.model_metrics import get_model_size, get_model_sparsity, get_yolo_metrics\n",
        "import os\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mlflow tracking server connection"
      ],
      "metadata": {
        "id": "3CdzFsjQuYkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USER_NAME = \"PredelinaAsya\" #@param {type:\"string\"}\n",
        "\n",
        "#@title Enter the access token:\n",
        "\n",
        "ACCESS_TOKEN = \"f2ebeaf63f365d01d78564af598eb69c8561ce60\" #@param {type:\"string\"}\n",
        "\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = USER_NAME\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = ACCESS_TOKEN\n",
        "\n",
        "mlflow.set_tracking_uri('https://dagshub.com/PredelinaAsya/ModelCompression.mlflow')"
      ],
      "metadata": {
        "id": "hhfZvLn5uYEK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYdgdOWpZuyl"
      },
      "source": [
        "# ONNX: export and inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RebfcokZoXq",
        "outputId": "b8e0be92-8011-437c-b7cc-66d6be539d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 53.3MB/s]\n",
            "Ultralytics YOLOv8.0.190 ğŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.4s, saved as 'yolov8n.onnx' (12.2 MB)\n",
            "\n",
            "Export complete (4.0s)\n",
            "Results saved to \u001b[1m/content/ModelCompression/hw5\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "base_model = YOLO('yolov8n.pt')\n",
        "onnx_path = base_model.export(format=\"onnx\", device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3V9Vrx2ZuTb",
        "outputId": "3d6a525d-344c-4909-ee69-c5e44a5e569e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.190 ğŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Loading yolov8n.onnx for ONNX Runtime inference...\n",
            "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n",
            "\n",
            "Dataset 'coco128.yaml' images not found âš ï¸, missing path '/content/ModelCompression/hw5/datasets/coco128/images/train2017'\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to '/content/ModelCompression/hw5/datasets/coco128.zip'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.66M/6.66M [00:00<00:00, 53.9MB/s]\n",
            "Unzipping /content/ModelCompression/hw5/datasets/coco128.zip to /content/ModelCompression/hw5/datasets/coco128...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 263/263 [00:00<00:00, 999.74file/s]\n",
            "Dataset download success âœ… (1.4s), saved to \u001b[1m/content/ModelCompression/hw5/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 13.4MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ModelCompression/hw5/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 533.91it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/ModelCompression/hw5/datasets/coco128/labels/train2017.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:38<00:00,  3.37it/s]\n",
            "                   all        128        929      0.651      0.532      0.606      0.452\n",
            "                person        128        254      0.805      0.667      0.764      0.543\n",
            "               bicycle        128          6      0.661      0.328      0.329      0.232\n",
            "                   car        128         46      0.817      0.196      0.269      0.181\n",
            "            motorcycle        128          5      0.602        0.8       0.88      0.672\n",
            "              airplane        128          6      0.756      0.667      0.845      0.619\n",
            "                   bus        128          7      0.539      0.714      0.698      0.625\n",
            "                 train        128          3      0.525      0.667       0.83      0.764\n",
            "                 truck        128         12      0.689       0.25       0.42      0.239\n",
            "                  boat        128          6      0.197      0.167      0.331      0.145\n",
            "         traffic light        128         14      0.684      0.157      0.202      0.139\n",
            "             stop sign        128          2      0.612        0.5      0.828      0.597\n",
            "                 bench        128          9      0.835      0.563      0.621      0.319\n",
            "                  bird        128         16      0.856      0.743      0.865      0.519\n",
            "                   cat        128          4      0.837          1      0.995      0.902\n",
            "                   dog        128          9      0.727      0.889      0.829        0.6\n",
            "                 horse        128          2      0.699          1      0.995      0.746\n",
            "              elephant        128         17      0.909      0.824      0.893      0.661\n",
            "                  bear        128          1       0.62          1      0.995      0.995\n",
            "                 zebra        128          4       0.85          1      0.995      0.971\n",
            "               giraffe        128          9      0.765          1      0.928      0.705\n",
            "              backpack        128          6       0.69       0.38      0.433      0.253\n",
            "              umbrella        128         18      0.649      0.444      0.641      0.405\n",
            "               handbag        128         19      0.409     0.0526      0.157     0.0878\n",
            "                   tie        128          7      0.849      0.714      0.719      0.478\n",
            "              suitcase        128          4      0.614          1      0.912      0.624\n",
            "               frisbee        128          5      0.691        0.8      0.759      0.688\n",
            "                  skis        128          1      0.661          1      0.995      0.497\n",
            "             snowboard        128          7      0.676      0.714      0.716      0.567\n",
            "           sports ball        128          6      0.536      0.167      0.469      0.282\n",
            "                  kite        128         10      0.632      0.348      0.444      0.178\n",
            "          baseball bat        128          4      0.649        0.5      0.502      0.274\n",
            "        baseball glove        128          7      0.638      0.429      0.429      0.309\n",
            "            skateboard        128          5      0.667        0.6      0.599      0.413\n",
            "         tennis racket        128          7      0.666      0.571      0.522      0.321\n",
            "                bottle        128         18      0.636      0.388      0.421      0.251\n",
            "            wine glass        128         16      0.533      0.375      0.493      0.329\n",
            "                   cup        128         36      0.699       0.25      0.416      0.283\n",
            "                  fork        128          6       0.57      0.167      0.254      0.188\n",
            "                 knife        128         16      0.642      0.438      0.611      0.389\n",
            "                 spoon        128         22      0.574      0.184      0.324      0.174\n",
            "                  bowl        128         28      0.722      0.607      0.627      0.475\n",
            "                banana        128          1          0          0      0.124     0.0465\n",
            "              sandwich        128          2      0.527          1      0.663      0.663\n",
            "                orange        128          4          1          0      0.995      0.666\n",
            "              broccoli        128         11      0.346      0.182      0.252      0.212\n",
            "                carrot        128         24       0.67      0.423      0.621      0.396\n",
            "               hot dog        128          2      0.473      0.918      0.745      0.721\n",
            "                 pizza        128          5      0.787          1      0.995      0.838\n",
            "                 donut        128         14      0.649          1      0.946      0.851\n",
            "                  cake        128          4      0.602          1      0.912      0.797\n",
            "                 chair        128         35      0.469      0.486      0.417      0.234\n",
            "                 couch        128          6      0.508        0.5      0.649      0.461\n",
            "          potted plant        128         14      0.588      0.643      0.686      0.455\n",
            "                   bed        128          3      0.933      0.667      0.736      0.576\n",
            "          dining table        128         13      0.423      0.538      0.507      0.425\n",
            "                toilet        128          2      0.605        0.5       0.62      0.596\n",
            "                    tv        128          2      0.401      0.702      0.745      0.696\n",
            "                laptop        128          3          1          0      0.244      0.194\n",
            "                 mouse        128          2          1          0     0.0694     0.0139\n",
            "                remote        128          8      0.816        0.5      0.608        0.5\n",
            "            cell phone        128          8          1          0      0.128     0.0745\n",
            "             microwave        128          3      0.336      0.675      0.806      0.702\n",
            "                  oven        128          5      0.378        0.4      0.363      0.284\n",
            "                  sink        128          6      0.328      0.167      0.156      0.103\n",
            "          refrigerator        128          5      0.711        0.4      0.603       0.42\n",
            "                  book        128         29      0.659      0.103      0.297      0.153\n",
            "                 clock        128          9      0.726      0.778      0.861      0.727\n",
            "                  vase        128          2      0.345          1      0.828      0.795\n",
            "              scissors        128          1          1          0      0.199     0.0564\n",
            "            teddy bear        128         21       0.65      0.355      0.586      0.389\n",
            "            toothbrush        128          5      0.894        0.6      0.706      0.433\n",
            "Speed: 2.9ms preprocess, 271.8ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def get_file_size_in_mb(path: str):\n",
        "  size_in_bytes = os.path.getsize(path)\n",
        "  size_in_mb = size_in_bytes / 2 ** 20\n",
        "  return size_in_mb\n",
        "\n",
        "onnx_model = YOLO(onnx_path, task='detect')\n",
        "\n",
        "with mlflow.start_run(run_name=\"onnx\") as run:\n",
        "  mlflow.log_param(\"compression_type\", \"onnx_convert\")\n",
        "  mlflow.log_metric(\"model_size\", get_file_size_in_mb(onnx_path))\n",
        "  mlflow.log_param(\"device\", \"cpu\")\n",
        "  mlflow.log_param(\"model_name\", \"yolov8n\")\n",
        "\n",
        "  onnx_metrics = onnx_model.val(data=\"coco128.yaml\", device='cpu')\n",
        "  onnx_metrics = get_yolo_metrics(onnx_metrics)\n",
        "  for key, val in onnx_metrics.items():\n",
        "    mlflow.log_metric(key, val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upHPYmV1eyAS"
      },
      "source": [
        "# OpenVINO: export and inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOQME4pSfCn8",
        "outputId": "6a237ed3-78f4-45b1-a8fd-1f1ee02c85c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.190 ğŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'yolov8n.onnx' (12.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2023.1.0-12185-9e6b00e51cd-releases/2023/1...\n",
            "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success âœ… 1.9s, saved as 'yolov8n_openvino_model/' (12.3 MB)\n",
            "\n",
            "Export complete (4.8s)\n",
            "Results saved to \u001b[1m/content/ModelCompression/hw5\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8n_openvino_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov8n_openvino_model imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ],
      "source": [
        "openvino_path = base_model.export(format=\"openvino\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7_VMvbvfb0z",
        "outputId": "d894d5af-797e-44e6-a7a0-e729d1af9d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.190 ğŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Loading yolov8n_openvino_model for OpenVINO inference...\n",
            "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ModelCompression/hw5/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:31<00:00,  4.01it/s]\n",
            "                   all        128        929      0.651      0.532      0.606      0.452\n",
            "                person        128        254      0.805      0.667      0.764      0.543\n",
            "               bicycle        128          6      0.661      0.328      0.329      0.232\n",
            "                   car        128         46      0.817      0.196      0.269      0.181\n",
            "            motorcycle        128          5      0.602        0.8       0.88      0.672\n",
            "              airplane        128          6      0.756      0.667      0.845      0.619\n",
            "                   bus        128          7      0.539      0.714      0.698      0.625\n",
            "                 train        128          3      0.525      0.667       0.83      0.764\n",
            "                 truck        128         12      0.689       0.25       0.42      0.239\n",
            "                  boat        128          6      0.197      0.167      0.331      0.145\n",
            "         traffic light        128         14      0.684      0.157      0.202      0.139\n",
            "             stop sign        128          2      0.612        0.5      0.828      0.597\n",
            "                 bench        128          9      0.835      0.563      0.621      0.319\n",
            "                  bird        128         16      0.856      0.743      0.865      0.519\n",
            "                   cat        128          4      0.837          1      0.995      0.902\n",
            "                   dog        128          9      0.727      0.889      0.829        0.6\n",
            "                 horse        128          2      0.699          1      0.995      0.746\n",
            "              elephant        128         17      0.909      0.824      0.893      0.661\n",
            "                  bear        128          1       0.62          1      0.995      0.995\n",
            "                 zebra        128          4       0.85          1      0.995      0.971\n",
            "               giraffe        128          9      0.765          1      0.928      0.705\n",
            "              backpack        128          6       0.69       0.38      0.433      0.253\n",
            "              umbrella        128         18      0.649      0.444      0.641      0.405\n",
            "               handbag        128         19      0.409     0.0526      0.157     0.0878\n",
            "                   tie        128          7      0.849      0.714      0.719      0.478\n",
            "              suitcase        128          4      0.614          1      0.912      0.624\n",
            "               frisbee        128          5      0.691        0.8      0.759      0.688\n",
            "                  skis        128          1      0.661          1      0.995      0.497\n",
            "             snowboard        128          7      0.676      0.714      0.716      0.567\n",
            "           sports ball        128          6      0.536      0.167      0.469      0.282\n",
            "                  kite        128         10      0.632      0.348      0.444      0.178\n",
            "          baseball bat        128          4      0.649        0.5      0.502      0.274\n",
            "        baseball glove        128          7      0.638      0.429      0.429      0.309\n",
            "            skateboard        128          5      0.667        0.6      0.599      0.413\n",
            "         tennis racket        128          7      0.666      0.571      0.522      0.321\n",
            "                bottle        128         18      0.636      0.388      0.421      0.251\n",
            "            wine glass        128         16      0.533      0.375      0.493      0.329\n",
            "                   cup        128         36      0.699       0.25      0.416      0.283\n",
            "                  fork        128          6       0.57      0.167      0.254      0.188\n",
            "                 knife        128         16      0.642      0.438      0.611      0.389\n",
            "                 spoon        128         22      0.574      0.184      0.324      0.174\n",
            "                  bowl        128         28      0.722      0.607      0.627      0.475\n",
            "                banana        128          1          0          0      0.124     0.0465\n",
            "              sandwich        128          2      0.527          1      0.663      0.663\n",
            "                orange        128          4          1          0      0.995      0.666\n",
            "              broccoli        128         11      0.346      0.182      0.252      0.212\n",
            "                carrot        128         24       0.67      0.423      0.621      0.396\n",
            "               hot dog        128          2      0.473      0.918      0.745      0.721\n",
            "                 pizza        128          5      0.787          1      0.995      0.838\n",
            "                 donut        128         14      0.649          1      0.946      0.851\n",
            "                  cake        128          4      0.602          1      0.912      0.797\n",
            "                 chair        128         35      0.469      0.486      0.417      0.234\n",
            "                 couch        128          6      0.508        0.5      0.649      0.461\n",
            "          potted plant        128         14      0.588      0.643      0.686      0.455\n",
            "                   bed        128          3      0.933      0.667      0.736      0.576\n",
            "          dining table        128         13      0.423      0.538      0.507      0.425\n",
            "                toilet        128          2      0.605        0.5       0.62      0.596\n",
            "                    tv        128          2      0.401      0.702      0.745      0.696\n",
            "                laptop        128          3          1          0      0.244      0.194\n",
            "                 mouse        128          2          1          0     0.0694     0.0139\n",
            "                remote        128          8      0.816        0.5      0.608        0.5\n",
            "            cell phone        128          8          1          0      0.128     0.0745\n",
            "             microwave        128          3      0.336      0.675      0.806      0.702\n",
            "                  oven        128          5      0.378        0.4      0.363      0.284\n",
            "                  sink        128          6      0.328      0.167      0.156      0.103\n",
            "          refrigerator        128          5      0.711        0.4      0.603       0.42\n",
            "                  book        128         29      0.659      0.103      0.297      0.153\n",
            "                 clock        128          9      0.726      0.778      0.861      0.727\n",
            "                  vase        128          2      0.345          1      0.828      0.795\n",
            "              scissors        128          1          1          0      0.199     0.0564\n",
            "            teddy bear        128         21       0.65      0.355      0.586      0.389\n",
            "            toothbrush        128          5      0.894        0.6      0.706      0.433\n",
            "Speed: 2.3ms preprocess, 226.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "openvino_model = YOLO(openvino_path, task='detect')\n",
        "\n",
        "with mlflow.start_run(run_name=\"openvino\") as run:\n",
        "  mlflow.log_param(\"compression_type\", \"openvino_convert\")\n",
        "  mlflow.log_metric(\"model_size\", get_file_size_in_mb(os.path.join(openvino_path, 'yolov8n.bin')))\n",
        "  mlflow.log_param(\"device\", \"cpu\")\n",
        "  mlflow.log_param(\"model_name\", \"yolov8n\")\n",
        "\n",
        "  openvino_metrics = openvino_model.val(data=\"coco128.yaml\", device='cpu')\n",
        "  openvino_metrics = get_yolo_metrics(openvino_metrics)\n",
        "  for key, val in openvino_metrics.items():\n",
        "    mlflow.log_metric(key, val)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}